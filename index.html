<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta
      name="description"
      content="Personalize Anything is a training-free framework for personalized image generation in DiT, enabling layout-guided generation, multi-subject personalization, and mask-controlled editing." />
    <meta
      name="keywords"
      content="Subject personalization, T2I Image Generation, Diffusion Models" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Personalize Anything for Free with Diffusion Transformer</title>

    <link
      href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
      rel="stylesheet" />

    <link rel="stylesheet" href="./static/css/bulma.min.css" />
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css" />
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css" />
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css" />
    <link rel="stylesheet" href="./static/css/academicons.min.css" />
    <link rel="stylesheet" href="./static/css/index.css" />
    <!-- <link rel="icon" href="./static/images/favicon.svg" /> -->

    <style>
      .render_wrapper {
        position: relative;
        height: 350px;
      }

      .conference {
        font-family: "Google Sans", sans-serif;
        color: hsl(240, 2%, 10%) !important;
        font-family: "Merriweather", serif;
        font-weight: 500;
      }

      .results-carousel textbox {
        font-size: 7px;
        font-family: "Google Sans", cursive, sans-serif;
        color: hsl(321, 56%, 56%) !important;
      }
      .dialog-box {
        background-color: rgba(255, 255, 255, 0.5);
        border: 1px solid rgba(96, 85, 85, 0.494);
        padding: 10px;
        border-radius: 15px;
        z-index: 1000;
        font-size: 14px;
        font-family: "Comic Sans MS", cursive, sans-serif;
        color: hsl(322, 33%, 22%) !important;
        font-weight: bold;
      }
    </style>

    <!-- Import the component -->
    <script
      type="module"
      src="https://ajax.googleapis.com/ajax/libs/model-viewer/3.1.1/model-viewer.min.js"></script>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS_HTML"></script>
  </head>
  <body>
    <nav class="navbar" role="navigation" aria-label="main navigation">
      <div class="navbar-brand">
        <a
          role="button"
          class="navbar-burger"
          aria-label="menu"
          aria-expanded="false">
          <span aria-hidden="true"></span>
          <span aria-hidden="true"></span>
          <span aria-hidden="true"></span>
        </a>
      </div>

      <div class="navbar-menu">
        <div class="navbar-start" style="flex-grow: 1; justify-content: center">
          <a class="navbar-item" href="https://github.com/huanngzh">
            <span class="icon">
              <i class="fas fa-home"></i>
            </span>
          </a>

          <div class="navbar-item has-dropdown is-hoverable">
            <a class="navbar-link"> More Research </a>
            <div class="navbar-dropdown">
              <a
                class="navbar-item"
                href="https://huanngzh.github.io/MV-Adapter-Page/"
                target="_blank">
                MV-Adapter
              </a>              
              <a
                class="navbar-item"
                href="https://huanngzh.github.io/EpiDiff/"
                target="_blank">
                EpiDiff
              </a>
              <a
                class="navbar-item"
                href="https://costwen.github.io/Ouroboros3D/"
                target="_blank">
                Ouroboros3D
              </a>
              <a
                class="navbar-item"
                href="https://huanngzh.github.io/MIDI-Page/"
                target="_blank">
                MIDI
              </a>
            </div>
          </div>
        </div>
      </div>
    </nav>

    <section class="hero">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column has-text-centered">
              <h1 class="title is-1 publication-title">
                Personalize Anything for Free with Diffusion Transformer
              </h1>
              <div class="is-size-5 publication-authors">
                <a
                  href="https://scholar.google.com/citations?user=riCXH64AAAAJ"
                  target="_blank"
                  >Haoran Feng</a
                ><sup>1</sup>,
                <a
                  href="https://scholar.google.com.hk/citations?user=U3VbX6kAAAAJ"
                  target="_blank"
                  >Zehuan Huang</a
                ><sup>2†✉</sup>,
                <a
                  href="https://scholar.google.com/citations?user=HL3uwegAAAAJ"
                  target="_blank"
                  >Lin Li</a
                ><sup>3</sup>, 
                <a href="https://www.au.tsinghua.edu.cn/info/1096/1543.htm" target="_blank"
                  >Hairong Lv</a
                ><sup>4</sup>,
                <a href="https://lucassheng.github.io/" target="_blank"
                  >Lu Sheng</a
                ><sup>2✉</sup>
              </div>

              <div class="is-size-5 publication-authors">
                <sup>1</sup>Tsinghua Shenzhen International Graduate School &nbsp;&nbsp;
                <sup>2</sup>School of Software, Beihang University &nbsp;&nbsp; <br>
                <sup>3</sup>School of Finance, Renmin University of China &nbsp;&nbsp; 
                <sup>4</sup>Department of Automation, Tsinghua University <br />
                <sup>†</sup>Project Lead &nbsp;&nbsp; <sup>✉</sup>Corresponding Authors
              </div>

              <div class="column has-text-centered">
                <div class="publication-links">
                  <!-- PDF Link. -->
                  <!-- <span class="link-block">
                    <a
                      href="https://arxiv.org/abs/2412.03632"
                      target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Paper</span>
                    </a>
                  </span> -->
                  <!-- Code Link. -->
                  <!-- <span class="link-block">
                    <a
                      href="https://github.com/huanngzh/MV-Adapter"
                      target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fab fa-github"></i>
                      </span>
                      <span>Code</span>
                    </a>
                  </span> -->
                  <!-- Model Link. -->
                  <!-- <span class="link-block">
                    <a
                      href="https://huggingface.co/huanngzh/mv-adapter"
                      target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fa fa-database"></i>
                      </span>
                      <span>Model</span>
                    </a>
                  </span> -->
                  <!-- Demo Link. -->
                  <!-- <span class="link-block">
                    <a
                      href="https://huggingface.co/collections/huanngzh/mv-adapter-spaces-677e497578747fd734a1b999"
                      target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="far fa-smile"></i>
                      </span>
                      <span>Demos</span>
                    </a>
                  </span> -->
                </div>
              </div>
              <div class="is-size-5 publication-authors">
                <hr
                  style="
                    width: 100%;
                    height: 0.7px;
                    background-color: rgba(0, 0, 0, 0.665);
                    margin-top: 1em;
                  " />
                  Create images with high text alignment, object consistency, diversity, and controllability using foundational T2I models.
                <!-- Create High-fidelity Multi-view Images with Various Base T2I Models and Various Conditions. -->
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <section class="hero is-light is-small">
      <div class="hero-body">
        <div class="container is-centered">
          <div class="has-text-centered">
            <img src="./images/teaser.png" class="" alt="" width="80%"/>
            <!-- <video
              id="dollyzoom"
              autoplay
              controls
              muted
              loop
              playsinline
              width="80%">
              <source src="./videos/teaser.mp4" type="video/mp4" />
            </video> -->
          </div>
          <div class="columns is-centered">
            <div class="column is-four-fifths">
              The images show our method's results in single-subject personalization, 
              layout-guided subject personalization, multi-subject personalization, and more, 
              demonstrating strong object consistency and controllability.
              <!-- <b>Row 1</b> shows results of our method in
              <font color="#3a86ff"
                ><b
                  >single-subject personalization</b
                ></font
              > and 
              <font color="#3a86ff"
                ><b
                  >layout-guided subject personalization</b
                ></font
              >. -->
              <!-- <b>Row 1</b> shows results by integrating MV-Adapter with
              <font color="#3a86ff"
                ><b
                  >personalized T2Is, distilled few-step T2Is, and
                  ControlNets</b
                ></font
              >, demonstrating its adaptability. <b>Row 2</b> shows results
              under various control signals, including
              <font color="#3a86ff"
                ><b>view-guided or geometry-guided</b>
              </font>
              generation with
              <font color="#3a86ff"><b>text or image inputs</b></font
              >, showcasing its versatility. -->
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- <section class="section">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-full-width">
            <video
              id="dollyzoom"
              autoplay
              controls
              muted
              loop
              playsinline
              width="100%">
              <source src="./videos/more_views.mp4" type="video/mp4" />
            </video>
            <br />
            <div class="has-text-centered">
              Here we show that MV-Adapter generates viewpoints with elevation
              ranging from 0 to 30 degrees.
            </div>
          </div>
        </div>
      </div>
    </section> -->

    <section class="section">
      <div class="container is-max-desktop">
        <!-- Abstract. -->
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Abstract</h2>
            <div class="content has-text-justified">
              <p>
                Personalized image generation aims to produce images of user-specified concepts while enabling flexible editing.
                Recent training-free approaches, while exhibit higher computational efficiency than training-based methods, 
                struggle with identity preservation, applicability, and compatibility with diffusion transformers (DiTs).
                In this paper, we uncover the untapped potential of DiT, where simply replacing denoising tokens with those of a reference subject achieves zero-shot subject reconstruction.
                This simple yet effective feature injection technique unlocks diverse scenarios, from personalization to image editing.
                Building upon this observation, we propose <b>Personalize Anything</b>, a training-free framework that achieves personalized image generation in DiT through:
                (1) timestep-adaptive token replacement that enforces subject consistency via early-stage injection and enhances flexibility through late-stage regularization, 
                and (2) patch perturbation strategies to boost structural diversity. 
                Our method seamlessly supports layout-guided generation, multi-subject personalization, and mask-controlled editing.
                Evaluations demonstrate state-of-the-art performance in identity preservation and versatility.
                Our work establishes new insights into DiTs while delivering a practical paradigm for efficient personalization.
              </p>
            </div>
          </div>
        </div>
        <!--/ Abstract. -->
      </div>
    </section>

    <section class="section">
      <div class="container is-max-desktop">
        <div class="has-text-centered">
          <h2 class="title is-3">Method</h2>
        </div>
        <br />
        <div class="columns is-centered">
          <div class="column is-full-width">
            <!-- <div class="column is-half">
              <img src="./assets/overview_inference.png" class="" alt="" />
            </div> -->
            <div>
              <img src="./images/pipeline.png" class="" alt="" />
            </div>
            <!-- <div class="column is-half">
              MV-Adapter is a plug-and-play adapter that learns multi-view priors
              transferable to derivatives of T2I models without
              <font color="#3a86ff"><b>specific tuning</b></font
              >, and enable T2Is to generate multi-view consistent images
              <font color="#3a86ff"><b>under various conditions</b></font
              >. At inference time, our MV-Adapter, which contains a condition
              guider <font color="#ffe699"><b>(yellow)</b></font> and the
              decoupled attention layers <font color="#bdd7ee"><b>(blue)</b></font
              >, can be directly inserted into a personalized or distilled T2I to
              constitute the multi-view generator.
            </div> -->
            <div>
              Personalize Anything anchors subject identity in early denoising through 
              <font color="#3a86ff"><b>mask-guided token replacement</b></font> 
              with preserved positional encoding, 
              and transitions to multi-modal attention for semantic fusion with text in later steps. 
              During token replacement, we inject variations via 
              <font color="#3a86ff"><b>patch perturbations</b></font>. 
              This timestep-adaptive strategy balances identity preservation and generative flexibility.
            </div>
          </div>
        </div>
        <div class="columns is-centered">
          <div class="column is-full-width">
            <br />
            <img src="./images/method_extensions.png" class="" alt="" />
            Our method enables: 
            (a) <font color="#3a86ff"><b>layout-guided generation</b></font> 
              by translating token-injected regions, 
            (b) <font color="#3a86ff"><b>multi-subject composition</b></font> 
              through sequential token injection, and 
            (c) <font color="#3a86ff"><b>inpainting</b></font> and <font color="#3a86ff"><b>outpainting</b></font> 
              via specifying masks and increased replacement.
          </div>
        </div>
      </div>
    </section>

    <section class="section">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-full-width">
            <div class="has-text-centered">
              <h2 class="title is-3">Qualitative Comparisons on Single-subject Personalization</h2>
            </div>
            <br />
            <img src="./images/full_experiment.png" class="" alt="" />
            <!-- <video autoplay controls muted loop playsinline height="100%">
              <source src="./videos/more_results_t2mv.mp4" type="video/mp4" />
            </video> -->
            <div>
              Our method produces high-fidelity images that are highly consistent with the specified subjects, without necessitating training or fine-tuning.
            </div>
          </div>
        </div>
      </div>
    </section>

    <section class="section">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-full-width">
            <div class="has-text-centered">
              <h2 class="title is-3">Qualitative Comparisons on Multi-subject Personalization</h2>
            </div>
            <br />
            <img src="./images/comparison_multi_subject.png" class="" alt="" />
            <!-- <video autoplay controls muted loop playsinline height="100%">
              <source src="./videos/more_results_i2mv.mp4" type="video/mp4" />
            </video> -->
            <div>
              Our method manages to maintain natural interactions among subjects via layout-guided generation, while ensuring each subject retains its identical characteristics and distinctiveness.
            </div>
          </div>
        </div>
      </div>
    </section>

    <section class="section">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-full-width">
            <div class="has-text-centered">
              <h2 class="title is-3">Qualitative Comparisons on Subject-scene Composition</h2>
            </div>
            <br />
            <img src="./images/comparison_subject_scene.png" class="" alt="" />
            <div>
            Our method successfully generates natural images while effectively preserving the details of the subjects.
            </div>
            <!-- <video autoplay controls muted loop playsinline height="100%">
              <source
                src="./videos/more_results_sketch2mv.mp4"
                type="video/mp4" />
            </video> -->
          </div>
        </div>
      </div>
    </section>

    <section class="section">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-full-width">
            <div class="has-text-centered">
              <h2 class="title is-3">More Applications</h2>
            </div>
            <br />
            <img src="./images/applications.png" class="" alt="" />
            <div>
              Our method naturally extends to diverse real-world applications, including subject-driven image generation with layout guidance, inpainting and outpainting.
            </div>           
            <!-- <video autoplay controls muted loop playsinline height="100%">
              <source
                src="./videos/more_results_text_to_3d.mp4"
                type="video/mp4" />
            </video> -->
          </div>
        </div>
      </div>
    </section>

    <section class="section">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-full-width">
            <div class="has-text-centered">
              <h2 class="title is-3">Ablation Study</h2>
            </div>
            <br />
            <img src="./images/ablation_study.png" class="" alt="" />
            <!-- <video autoplay controls muted loop playsinline height="100%">
              <source
                src="./videos/more_results_image_to_3d.mp4"
                type="video/mp4" />
            </video> -->
            <div>
              We conduct ablation studies on single-subject personalization, 
              examining the effects of token replacement timestep threshold 
              \( \tau \) 
              and the patch perturbation strategy.
            </div>
          </div>
        </div>
      </div>
    </section>

    <section class="section" id="BibTeX">
      <div class="container is-max-desktop content">
        <div class="has-text-centered">
          <h2 class="title">BibTeX</h2>
        </div>
        <div
          class="columns is-centered has-text-centered"
          style="padding-bottom: 1.5rem">
          <div class="column is-four-fifths">
            <div class="content has-text-justified">
              <pre><code>
                waiting
              </code></pre>
            </div>
          </div>
        </div>
      </div>
    </section>

    <footer class="footer">
      <div class="container">
        <div class="content has-text-centered">
          <!-- <a class="icon-link" href="">
            <i class="fas fa-file-pdf"></i>
          </a> -->
          <a
            class="icon-link"
            href="https://github.com/huanngzh"
            class="external-link"
            disabled>
            <i class="fab fa-github"></i>
          </a>
        </div>
        <div class="columns is-centered">
          <div class="column is-8">
            <div class="content">
              <p style="text-align: center">
                Source code of this page can be found at
                <a
                  href="https://github.com/DHUAVY/Personalize-Anything-Page"
                  target="_blank"
                  >Personalize-Anything-Page</a
                >. The website template is forked from
                <a href="https://github.com/huanngzh/MV-Adapter-Page" target="_blank">MV-Adapter-Page</a
                >.
              </p>
            </div>
          </div>
        </div>
      </div>
    </footer>
  </body>
</html>
